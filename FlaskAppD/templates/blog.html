<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Blog - Algorithmic Bias</title>

    <!-- Bootstrap Core CSS -->
    <link href="../static/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="../static/css/business-casual.css" rel="stylesheet">

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Josefin+Slab:100,300,400,600,700,100italic,300italic,400italic,600italic,700italic" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <div class="brand">Algorithmic Bias</div>
    <div class="address-bar">Rebecca Njeri | Seattle, WA | 206.565.7666</div>

    <!-- Navigation -->
    <nav class="navbar navbar-default" role="navigation">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <!-- navbar-brand is hidden on larger screens, but visible when the menu is collapsed -->
                <a class="navbar-brand" href="/">Algorithmic Bias</a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    <li>
                        <a href="/blog">Blog</a>
                    </li>
                    <li>
                        <a href="/contact">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <div class="container">

        <div class="row">
            <div class="box">
                <div class="col-lg-12">
                    <hr>
                    <h2 class="intro-text text-center">
                        <strong>Algorithmic Bias</strong>
                    </h2>
                    <hr>
                </div>
                <div class="col-lg-12 text-center">
                    <img class="img-responsive img-border img-full" src="../static/img/slide-3a.jpg" alt="">
                    <h2>Algorithmic Bias
                        <br>
                        <small>March 26, 2017</small>
                    </h2>
                    <p>
                    <b>Algorithmic Bias</b>
                    <p>"A vetted methodology for avoiding discrimination against protected attributes in machine learning is lacking." -Hardt, Price, Srebro (Equality of opportunity in supervised learning.)</p>
                    <p><b>How I Found Myself Here</b></p>
                    </p>
                    <p>
                      I found myself here accidentally on purpose. I began this project as a volunteer for the Post Prison Education program which aims to reduce recidivism among former inmates.Once I had access to the data, the first thing I did was create a recidivism prediction model, with the aim of showing reduced recidivism rates against the general population. After I had developed a terribly performing model due to data limitations, I discovered that the existing recidivism prediction models are critiqued for their inherent bias. Why is an algorithm that has a racially disparate impact implemented in the judicial system? Why can't these algrothims be improved to correct bias? I discovered that there are not only disparate accuracy models for black versus white individuals, but also for black versus white neighborhoods. Heat maps produced by PredPol increase policing of black neighborhoods.
                    </p>
                    <p><b>
                    Business Understanding
                    </b></p>
                    <p>
                      This project has two scopes. The first one is to arrive at an estimate of the true cost of incarceration, and the second is to come up with a precise and sensitive way to predict recidivism. The end goal is to create a cost benefit analysis for the Post Prison Education Program that shows how investment in PPEP could ultimately lower the total cost of incarceration by lowering recidivism rates, but also by providing skills and social networks that are lost while one is incarcerated.
                    </p>
                    <p>
                      Recidivism prediction isn't a new field of study. There are researchers who have developed risk assessment tools that estimate the probability that a person will reoffend. These tools are used at all levels of the justice system from pre-trial to sentensing. However, a study by prorepublica found that while these models have an accuracy score of 71%, they output a lot higher False Positives for African Americans and False Negatives for whites when it comes to prediciting the likelihood of someone to commit a violent crime in the future. The pro publica study found that the model has a lot more false positives, 44.9% for African Americans, compared to 23.5% for whites. At the same time, the algorithm has a 47.7% False Negative rate for whites compared to a 28.0% False Negative rate for blacks.
                    </p>
                    <p>
                    Use of a faulty algorithm in the justice system results in a misallocation of resources by identifying as high risk people who aren't high risk and vice versa. Can an algorithm that predicts recidivism and risk levels with higher precision and recall be built?
                    </p>
                    <p>
                      "What they additionally need to do is to measure accuracy within different subgroups. Wildly differing performance across different groups of the population can indicate a problem... Indeed, some observers have called on the organizations that write and use algorithms to be more transparent in terms of clearly spelling out the data collected, identifying which pieces of data are used in the algorithm, and disclosing how this data is weighted or used in the algorithm. Such insights may help to pinpoint areas of discrimination that may not be apparent otherwise."
                    </p>
                    <p>
                      <b>
                        Data Understanding & Methodolody
                      </b>
                    </p>
                    <p>
                      The first thing I needed to acknowledge about the data is that it is not representative of racial proportions in Washington state. I realized that the data set was a self selected group who had opted to apply to the Post Prison Education Program with the goal of changing their lives. I tried to be very conscious of the effect the data set would have on the trained predictive algorithm. I wanted to understand the difference in recidivisms for each demographic that was represented in the data. After reading about what caused the disparate error rates in the recidivism prediction models, it seemed that training the entire population while ignoring the disparity in recidivism rates for different demographics led to creation of a biased model.
                    </p>
                    <p>
                      <b>
                          Building Better Prediction Models
                      </b>
                    </p>
                    <p>
How do we prevent bias from leaking into the prediction models while so many factors considered to be predictors are correlated with race?
The original recidivism prediction models were done using random forest classifiers. I used gradient boosting classifiers which have a higher accuracy on the test data than the random forest classifiers.
The goal is that with access to more data, the precision of the model can be improved to provide more accurate recidivism predictions.
                    </p>
                    <a href="#" class="btn btn-default btn-lg">Read More</a>
                    <hr>
                </div>
                <div class="col-lg-12 text-center">
                    <ul class="pager">
                        <li class="previous"><a href="#">&larr; Older</a>
                        </li>
                        <li class="next"><a href="#">Newer &rarr;</a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

    </div>
    <!-- /.container -->

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <p>Copyright &copy; Rebecca Njeri 2017</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="../static/js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="../static/js/bootstrap.min.js"></script>

</body>

</html>
