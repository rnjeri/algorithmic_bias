#Machine Bias
Risk level assessment tools are used at all levels of the justice system from pre-trial to sentensing. A study by prorepublica found that these models have an accuracy score of 71%, a score that varies for different races. 
Risk levels are used to determine how likely someone is to re-offend in the future, and how likely they are to commit a violent crime in the future. Other than accuracy scores, an important measure of model performance for such risk classification is precision and recall. The prorepublica study found that the model has a lot more false negatives, 44.9% for African Americans, compared to 23.5% for whites. When judges take the risk level score into account when making their judgement, these African Americans misclassified as likely to offend are penalized for a faulty algorithm. 
 

# Cost of Incarceration
What is the true cost of incarceration?
What features are most correlated with recidivism?

#
